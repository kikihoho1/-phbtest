#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
rag.py â€“ FAISS + Gemini ê¸°ë°˜ RAG ì±—ë´‡ (Elasticsearch ì œê±°)
2025â€‘06â€‘13
"""
from __future__ import annotations

import json
import logging
import os
import sys
from collections import defaultdict
from dataclasses import dataclass, asdict, field
from typing import Dict, List, Optional, Tuple

from dotenv import load_dotenv

load_dotenv()  # GOOGLE_API_KEY ë“± í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import faiss
    from sentence_transformers import SentenceTransformer, CrossEncoder
    from langchain_google_genai import ChatGoogleGenerativeAI
except ImportError as e:
    sys.stderr.write(
        f"ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {e}\n"
        "pip install faiss-cpu sentence-transformers langchain-google-genai python-dotenv\n"
    )
    sys.exit(1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FAISS_INDEX_PATH = "company_rules.faiss"
ARTICLES_DATA_PATH = "company_rules.json"

EMBEDDING_MODEL_NAME = "jhgan/ko-sroberta-multitask"
CROSS_ENCODER_MODEL = "kiyoungkim/ko-kce-cross-encoder"
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

TOP_K_SEARCH = 20
TOP_K_RERANK = 5

logging.basicConfig(level=logging.INFO, format="%(asctime)s â€” %(levelname)s â€” %(message)s")
logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ëª¨ë¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@dataclass(slots=True)
class LegalArticle:
    law_name: str
    law_id: str
    article_number: str
    paragraph_number: str
    content: str
    references: List[str]
    chapter: str = ""
    section: str = ""
    promulgation_date: str = ""
    enforcement_date: str = ""
    subparagraph_number: str = ""
    item_number: str = ""
    subsection: str = ""
    page_number: int = 0
    confidence_score: float = 1.0
    original_text: str = ""
    _ref_cache: str = field(init=False, repr=False)

    def __post_init__(self) -> None:
        self._ref_cache = f"{self.law_name} {self.article_number} {self.paragraph_number}".strip()

    def get_full_reference(self) -> str:
        return self._ref_cache


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²€ìƒ‰Â (FAISS ì „ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class VectorSearch:
    def __init__(self, index_path: str, model_name: str = EMBEDDING_MODEL_NAME):
        self.idx = faiss.read_index(index_path)
        self.embedder = SentenceTransformer(model_name)

    def search(self, query: str, k: int = TOP_K_SEARCH) -> List[Tuple[int, float]]:
        emb = self.embedder.encode([query], convert_to_numpy=True).astype("float32")
        faiss.normalize_L2(emb)
        scores, idxs = self.idx.search(emb, k)
        return [(int(i), float(s)) for i, s in zip(idxs[0], scores[0]) if i != -1]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìž¬ìˆœìœ„í™” (ì„ íƒ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class CrossReranker:
    def __init__(self, model_name: str = CROSS_ENCODER_MODEL):
        try:
            self.model = CrossEncoder(model_name)
        except Exception:
            self.model = None
            logger.warning("Crossâ€‘Encoder ë¡œë“œ ì‹¤íŒ¨ â†’ rerank ìƒëžµ")

    def rerank(self, query: str, articles: List[LegalArticle], idxs: List[int], k: int = TOP_K_RERANK) -> List[int]:
        if not self.model:
            return idxs[:k]
        pairs = [(query, articles[i].content) for i in idxs]
        scores = self.model.predict(pairs, show_progress_bar=False)
        ranked = sorted(zip(idxs, scores), key=lambda x: x[1], reverse=True)
        return [idx for idx, _ in ranked[:k]]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM ì‘ë‹µ (Gemini)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AnswerGenerator:
    def __init__(self, api_key: Optional[str] = GOOGLE_API_KEY, model_name: str = "gemini-1.5-pro-latest"):
        if api_key:
            os.environ["GOOGLE_API_KEY"] = api_key
            try:
                self.llm = ChatGoogleGenerativeAI(model=model_name, temperature=0.2)
                self.use_api = True
            except Exception as e:
                logger.warning(f"Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.use_api = False
        else:
            logger.warning("GOOGLE_API_KEY ì—†ìŒ â€“ í…œí”Œë¦¿ ëª¨ë“œ")
            self.use_api = False

    def generate(self, query: str, articles: List[LegalArticle]) -> str:
        if not articles:
            return "ê´€ë ¨ ê·œì •/ë²•ë ¹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        cites = "\n".join(f"- **{a.get_full_reference()}**: {a.content}" for a in articles)

        if not self.use_api:
            return f"[í…œí”Œë¦¿]\n{cites}"

        prompt = (
            "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë²•ë¥  ì „ë¬¸ê°€ AIìž…ë‹ˆë‹¤.\n"
            "ë‹¤ìŒ [ê·¼ê±°]ë§Œì„ í™œìš©í•´ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\n\n"
            f"[ì§ˆë¬¸]\n{query}\n\n[ê·¼ê±°]\n{cites}"
        )
        try:
            result = self.llm.invoke(prompt)
            if hasattr(result, "content"):
                return result.content.strip()
            return str(result).strip()
        except Exception as e:
            logger.error(f"Gemini ì˜¤ë¥˜: {e}")
            return "[Gemini í˜¸ì¶œ ì‹¤íŒ¨]"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RAG ì‹œìŠ¤í…œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class LegalRAG:
    def __init__(self) -> None:
        if not (os.path.exists(FAISS_INDEX_PATH) and os.path.exists(ARTICLES_DATA_PATH)):
            raise FileNotFoundError("index.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•´ FAISS/JSONì„ ìƒì„±í•˜ì„¸ìš”.")

        # LegalArticleì— ì •ì˜ëœ í•„ë“œë§Œ ì¶”ì¶œí•´ì„œ ê°ì²´ ìƒì„±
        self.articles: List[LegalArticle] = [
            LegalArticle(**{k: v for k, v in d.items() if k in LegalArticle.__dataclass_fields__})
            for d in json.load(open(ARTICLES_DATA_PATH, encoding="utf-8"))
        ]

        self.searcher = VectorSearch(FAISS_INDEX_PATH)
        self.reranker = CrossReranker()
        self.generator = AnswerGenerator()

        # ì°¸ì¡° í™•ëŒ€ìš© ë§µ
        self._map: Dict[str, LegalArticle] = {a.get_full_reference(): a for a in self.articles}

    # (ì„ íƒ) ë‚´ë¶€ ì°¸ì¡° ì¡°í•­ í™•ìž¥
    def _expand(self, selected: List[LegalArticle]) -> List[LegalArticle]:
        queue = list(selected)
        out = {a.get_full_reference(): a for a in selected}
        while queue:
            a = queue.pop()
            for ref in a.references:
                key = f"{a.law_name} {ref}"
                if key in self._map and key not in out:
                    out[key] = self._map[key]
                    queue.append(self._map[key])
        return list(out.values())

    def ask(self, question: str) -> str:
        idxs = [idx for idx, _ in self.searcher.search(question, TOP_K_SEARCH)]
        idxs = self.reranker.rerank(question, self.articles, idxs)
        answer_articles = self._expand([self.articles[i] for i in idxs])
        return self.generator.generate(question, answer_articles)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main() -> None:
    print("ðŸ›ï¸  ë²•ë ¹ RAG ì±—ë´‡ (ES ì—†ìŒ) â€“ quit/exitë¡œ ì¢…ë£Œ")
    rag = LegalRAG()
    while True:
        q = input("\nì§ˆë¬¸> ").strip()
        if q.lower() in {"quit", "exit"}:
            break
        if q:
            print("\n[ë‹µë³€]\n" + rag.ask(q))


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nì¢…ë£Œí•©ë‹ˆë‹¤.")
